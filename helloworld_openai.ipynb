{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRANmRMOPwO9XQFOhLpe+3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhogaai-agenticai-sathishkumar/genaicourse/blob/main/helloworld_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load the API key from Colab secrets\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "print(\"OPENAI_API_KEY = \" + OPENAI_API_KEY)\n",
        "print(\"*\"*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSEnJdHo3rYE",
        "outputId": "d380d97e-9141-4c5b-d55a-66aab949989b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY = 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\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJhNgvpcGQKI",
        "outputId": "749e05a1-582c-4b33-8994-cd8ac4a1788a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.99.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "OpenAI client initialized.\n",
            "****************************************************************************************************\n"
          ]
        }
      ],
      "source": [
        "# Install the OpenAI library\n",
        "!pip install openai\n",
        "\n",
        "# Import the OpenAI library and initialize the client\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "print(\"OpenAI client initialized.\")\n",
        "print(\"*\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    input=\"Tell me about yourself and the model name.\"\n",
        ")\n",
        "\n",
        "print(response.output_text)\n",
        "print(\"*\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80NmzPatuNZb",
        "outputId": "bfc5e85e-5bc6-4cc7-b456-bbd541b6f4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I’m an AI assistant created by OpenAI. I can help with questions, explanations, writing, coding, math and data reasoning, and I can also analyze images you share. I aim to be helpful and safe, but I can make mistakes and I don’t have access to personal data unless you provide it in the conversation.\n",
            "\n",
            "As for the model name: I don’t have visibility into the exact model identifier from within this chat. If you need the precise name, please check the app’s settings or the API request’s model field.\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    input=\"What is the current date?.\"\n",
        ")\n",
        "\n",
        "print(response.output_text)\n",
        "print(\"*\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA5eDQwSuc_E",
        "outputId": "5f2b9571-3860-41fb-9b06-45082c7dba9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "August 17, 2025.\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    input=\"Explain the importance of fast LLM inference.\"\n",
        ")\n",
        "\n",
        "print(response.output_text)\n",
        "print(\"*\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9625bfc5-1982-4ac7-a96b-e902817deddc",
        "id": "wSFt5-kEudoD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast LLM inference isn’t just a convenience—it determines what kinds of products you can build, how well they work, and whether they’re affordable to run. Key reasons it matters:\n",
            "\n",
            "- User experience and engagement\n",
            "  - Humans perceive delays in bands: ~100 ms feels instant, ~1 s keeps flow, >10 s breaks attention. LLM apps that respond quickly are trusted and used more.\n",
            "  - Time to first token (TTFT) shapes perceived speed; tokens-per-second shapes overall feel. Streaming lowers perceived latency and helps users stay engaged.\n",
            "  - Some modalities have hard budgets: code completion needs sub-100–300 ms for usefulness; voice assistants need roughly <200–300 ms end-to-end to feel natural.\n",
            "\n",
            "- Product capability\n",
            "  - Fast single calls enable multi-step workflows: tool use, retrieval-augmented generation, reranking, and multi-agent loops. Each extra call adds latency; faster inference compounds across steps.\n",
            "  - Real-time interactivity becomes possible: live document editing, pair programming, in-call assistance, and conversational search with follow-ups.\n",
            "  - On-device and edge scenarios (privacy/offline) are only viable if inference is fast and efficient.\n",
            "\n",
            "- Economics and scale\n",
            "  - Higher throughput (tokens/sec per accelerator) lowers cost per request and per token, enabling free tiers and broader adoption.\n",
            "  - Better latency reduces queueing and tail latency (P95/P99), improving SLAs without overprovisioning hardware.\n",
            "  - Energy efficiency improves with optimized, faster inference.\n",
            "\n",
            "- Quality and safety trade space\n",
            "  - When inference is fast, you can afford larger models, deeper reasoning, or more verification steps within the same latency budget.\n",
            "  - You can keep humans in the loop—show partial outputs, accept corrections, and interrupt or steer generation—without frustrating delays.\n",
            "  - Guardrails and content filtering can run concurrently or iteratively without blowing up response times.\n",
            "\n",
            "- Developer velocity\n",
            "  - Faster iteration for prompt and system design, A/B tests, and evaluation loops shortens time-to-value and improves model quality over time.\n",
            "  - Batch generation tasks (synthetic data, indexing, test cases) complete sooner, accelerating experimentation.\n",
            "\n",
            "- Competitive differentiation\n",
            "  - Speed directly correlates with user retention, satisfaction, and conversion. In crowded markets, agility and responsiveness are visible advantages.\n",
            "\n",
            "What to measure\n",
            "- TTFT (time to first token), tokens/sec during streaming, end-to-end latency including retrieval/tool calls, and tail latency (P95/P99). Optimize these, not just averages.\n",
            "\n",
            "Common ways teams achieve fast inference (high-level)\n",
            "- Model and runtime: quantization, distillation/smaller variants, sparsity/MoE, efficient attention and KV caching, speculative decoding.\n",
            "- Serving: continuous batching, prefix/KV cache reuse, optimized kernels, high-throughput runtimes, and streaming transports.\n",
            "- System design: reduce external round-trips, cache retrievals, co-locate components, and parallelize tool calls when possible.\n",
            "\n",
            "Bottom line: Fast inference expands what’s possible, makes experiences feel natural, and keeps costs under control—turning LLMs from demos into durable, scalable products.\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    input=\"Write a good bedtime story about a stars and space.\"\n",
        ")\n",
        "\n",
        "print(response.output_text)\n",
        "print(\"*\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOJyE6fR32x1",
        "outputId": "d2dea483-5420-4e6b-93c3-04a5756bbcbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tonight, the sky is a deep blue blanket, smooth and soft, with tiny silver stitches all across it. The window is open just a little, and the curtains breathe in and out like the tide. On your pillow, your eyes are wide, not quite ready for sleep.\n",
            "\n",
            "Tap, tap, tap.\n",
            "\n",
            "Something gentle taps the glass. You sit up and there, floating right outside the window, is a very small star. It is no bigger than your palm, with a warm, honey-colored glow and a tail like a sparkler at a birthday cake.\n",
            "\n",
            "“Hello,” says the star in a voice as light as dust. “My name is Wick. I’m a walker of the night. Would you like to come along while I make my rounds?”\n",
            "\n",
            "You peek at your blanket, and it peeks back, and you nod. Wick wobbles closer until his glow wraps you up like a shawl. The room tilts just a little, and together you drift through the window, up past the sleepy roof and the yawning trees.\n",
            "\n",
            "The air above the house is cool and kind. The moon leans on its elbow atop the edge of a cloud and smiles down. The Milky Way is a pale river, spreading its quiet light in a silver hush.\n",
            "\n",
            "“First,” Wick whispers, “we visit the Constellation Choir. They like to be sure their stories are remembered.”\n",
            "\n",
            "High above the rooftops, the stars arrange themselves into familiar shapes. The Bear curls her big bright paws under her chin and hums a low, warm note. The Hunter sets his bow beside him and plucks his belt like the strings of a harp. The Twins stack their shoulders together, giggling softly in the same breath. Each of them tells their tale, but so gently and so slowly that the words feel like feathers landing.\n",
            "\n",
            "You float through the stories, and they swish around you like a long, comfortable robe. Wick turns a little as you travel, and each time he turns, the sky shows a new wonder.\n",
            "\n",
            "Here, a comet drifts by, its tail a pale brush painting one soft stroke across the night. “She carries cool snow from the high halls,” Wick says. “For any star whose light got too warm today.”\n",
            "\n",
            "Below, a cluster of little stars flutters like a nest of golden bees. “They’re new,” Wick murmurs. “Fresh sparks. The Night Gardener planted them weeks ago.” You look, and there he is, a kind figure with boots made of midnight and a watering can like a silver moon. He tips it, and dew settles on the smallest stars, and they sigh as if sipping tea.\n",
            "\n",
            "You drift to the Rings. They circle a far planet like curly pieces of ribbon. Children of Saturn swing from them quietly, bare toes brushing the glitter, laughing in that breathless way laughter has when it knows the neighbors are sleeping. You smile and wish you could try a swing, just once.\n",
            "\n",
            "“We can’t stay long,” Wick says. “Everyone has their work at night.”\n",
            "\n",
            "“What is your work?” you ask, keeping your voice small so it doesn’t bump into any dreams.\n",
            "\n",
            "“I make sure the lights are comfortable,” he says. “Not too bright, not too dim, and always pointed where they’re needed. See there?” He nods toward a lonely lighthouse on a far shore. Its beam sweeps the dark water. “Sailors look for that. If a cloud’s too thick, I slip a star through so the beam still finds a way.”\n",
            "\n",
            "“Do you ever sleep?” you wonder.\n",
            "\n",
            "“Oh yes,” Wick says, with a smile you can feel rather than see. “But I nap in pockets of quiet, the same way a cat naps in sunbeams.”\n",
            "\n",
            "You pass through a hush so deep it’s almost a song. Out of that hush rises a whale made entirely of night, slow as a lullaby, carrying a school of minnows shaped like little wishes. Their tails tickle your cheeks as they pass. Each wish has a name stitched to its side, and you glimpse your own name, tiny and shining, sewn in careful thread.\n",
            "\n",
            "“There you are,” Wick whispers, as if he’s been expecting it. “Everyone has one.”\n",
            "\n",
            "On you go, through the curtain of the Aurora, which waves its green and pink hands like silk scarves in a breeze. Giant snow-quiet mountains down below glow with soft color. Somewhere, a long way off, a fox yawns, and a child in a cabin turns over and smiles in their sleep, and you feel, for a moment, wrapped up with all the sleepers everywhere.\n",
            "\n",
            "It’s nearly time to turn back, and Wick guides you toward the moon. Up close, the moon’s face is not a face at all but a quilt of gentle valleys and old, soft craters. Sitting on a ledge is a woman with a lap full of silver thread. She is mending a small tear in the night where a careless rocket snagged it.\n",
            "\n",
            "“Almost done,” she says, and her eyes twinkle like new pins. “There. That will hold till morning.” She pats the air and the night looks smooth again.\n",
            "\n",
            "“Thank you,” Wick says, and the moon-woman nods. “Travel safely, little flame,” she tells him. Then she looks at you and adds, “And you, little dreamer. Take this.”\n",
            "\n",
            "She hands you a spool of thread so fine it’s almost only a feeling. It hums in your palm like a purring kitten.\n",
            "\n",
            "“For when the night seems far away,” she says. “Pull a little from the spool and stitch a bit of darkness right where you need it, and sleep will find you.”\n",
            "\n",
            "You tuck the spool into your pocket. It is warm, the way bread is warm when it first comes from the oven.\n",
            "\n",
            "On the way home, you pass the Dawn Cupboard, where a quiet keeper is folding the morning inside out. The edges of the sky blush pink and gold. Birds clear their throats down on the branches below. A single light in a kitchen flicks on; someone is filling a kettle.\n",
            "\n",
            "“It’s time,” Wick whispers, and his glow becomes softer, like breathing. “The day is very good at looking after things. But the stars like to remain, just out of sight, listening.”\n",
            "\n",
            "You slip back through your window as the curtains take a slow breath. Your bed is exactly where you left it, the pillow a cool, kind cloud. You lie down and the mattress remembers you and cuddles you in.\n",
            "\n",
            "Wick hovers by the window. “When you close your eyes,” he says, “you’ll still be traveling. Your thoughts will sail the river roads of the Milky Way, and the Night Gardener will tip a sip of dew onto your forehead so your dreams grow. If dawn feels too quick, remember your spool—just a little darkness is enough.”\n",
            "\n",
            "“Will you come again?” you ask, and your voice is already dimming.\n",
            "\n",
            "“I am always near,” he answers. “Even if you can’t see me through the clouds. We are patient flames. We keep watch.”\n",
            "\n",
            "He taps the window, once, twice, three times, and then he melts into the quiet sky. The moon leans back, satisfied. The Constellation Choir hums a final, barely-there chord. The rings settle. The whale’s tail makes one last, slow arc. The wishes sparkle in their sleep with the names they carry.\n",
            "\n",
            "Inside the deep blue blanket of the night, your name glows for a moment and then softens, softens, softens, until it is part of everything that is gentle.\n",
            "\n",
            "Your eyes drift closed. The room is the universe in small. The air tastes like peace. And somewhere, far above and not far at all, a very small star adjusts the dimmer on the sky, just so, and the world sighs.\n",
            "\n",
            "Good night. Sleep, little traveler. The stars are awake. They will keep your dreams.\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    input=\"What was my previous question?\"\n",
        ")\n",
        "\n",
        "print(response.output_text)\n",
        "print(\"*\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXCZBwiG3m-B",
        "outputId": "0e1ad6c0-7dd6-411f-b512-e0b701a04027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don’t see any previous messages in this chat—only your current question. If you repeat your earlier question here, I’ll help right away.\n",
            "**************************************************\n"
          ]
        }
      ]
    }
  ]
}